{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now this notebook simply makes a network. For more examples see train.py in protein_holography/network. For how the network works see network/hnn and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import protein_holography.network.clebsch as clebsch\n",
    "import protein_holography.network.hnn as hnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hnn n classes = 20\n",
      "[<linearity.Linearity object at 0x64e3a9cd0>, <spherical_batch_norm.SphericalBatchNorm object at 0x64e99a650>, <nonlinearity.Nonlinearity object at 0x64ea8c110>, <linearity.Linearity object at 0x64dca2c50>, <spherical_batch_norm.SphericalBatchNorm object at 0x64ea8ca50>, <nonlinearity.Nonlinearity object at 0x64ea9b190>, <tensorflow.python.keras.layers.core.Dropout object at 0x64ea9b590>, <tensorflow.python.keras.layers.core.Dense object at 0x64ea9ba10>]\n"
     ]
    }
   ],
   "source": [
    "# parameters of the network\n",
    "\n",
    "netL = 2 # largest spherical frequency used in the network\n",
    "scale = 1. # scaling from before batch normalization days\n",
    "dropout = .4 # dropout in last feed forward layer\n",
    "reg = 1e-4 # regularization throughout the network\n",
    "n_dense = 1 # number of feed forward layers at end of CG net\n",
    "nlayers = 2 # number of CG layers\n",
    "hdim = 100 # number of channels in CG layer outputs\n",
    "learnrate = 1e-4 \n",
    "nclasses = 20 # number of classes for classification task (i.e. feed forward output dimension)\n",
    "datadir = '../data'\n",
    "cg_file = os.path.join(datadir, \"CG_matrix_l=13.npy\")\n",
    "tf_cg_matrices = clebsch.load_clebsch(cg_file, netL) # clebsch gordan matrices for doing direct products\n",
    "\n",
    "hidden_l_dims = [[hdim] * (netL + 1)] * nlayers\n",
    "\n",
    "network = hnn.hnn(netL,hidden_l_dims,nlayers,\n",
    "                  nclasses,tf_cg_matrices,n_dense,\n",
    "                  reg,dropout,scale\n",
    "                 )\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learnrate)\n",
    "#tf.function\n",
    "def loss_fn(truth, pred):\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels = truth,\n",
    "        logits = pred)\n",
    "\n",
    "network.compile(optimizer=optimizer,\n",
    "                loss=loss_fn,\n",
    "                metrics =['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
